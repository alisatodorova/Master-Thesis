True
1
NVIDIA GeForce RTX 3050 Laptop GPU
4095.5
Using device: cuda
DATASET SUMMARY
Number of classes        : 47
Class labels             : ['addisplay', 'addisplay++adware', 'adload', 'adsware', 'adware', 'adware++adware', 'adware++grayware++virus', 'adware++virus', 'adwareare', 'backdoor', 'banker++trojan', 'benign', 'click', 'clicker', 'clicker++trojan', 'clickfraud++riskware', 'downloader', 'dropper++trojan', 'exploit', 'fakeangry', 'fakeapp', 'fakeapp++trojan', 'fakeinst++trojan', 'gray', 'hacktool', 'malware', 'malware++trj', 'monitor', 'ransom++trojan', 'risktool++riskware++virus', 'riskware', 'riskware++smssend', 'rog', 'rootnik++trojan', 'smssend', 'smssend++trojan', 'spr', 'spy', 'spy++trojan', 'spyware', 'trj', 'troj', 'trojan', 'trojandownloader', 'trojandropper', 'virus', 'worm']
Train samples            : 883416
Validation samples       : 126202
Test samples             : 252406
Train class distribution : {0: 12221, 1: 206, 2: 233, 3: 1856, 4: 619118, 5: 1752, 6: 585, 7: 192, 8: 106, 9: 421, 10: 774, 11: 55383, 12: 79, 13: 186, 14: 2007, 15: 258, 16: 3498, 17: 414, 18: 3907, 19: 148, 20: 298, 21: 179, 22: 503, 23: 645, 24: 379, 25: 1754, 26: 426, 27: 950, 28: 807, 29: 106, 30: 22236, 31: 173, 32: 1382, 33: 156, 34: 2286, 35: 3006, 36: 9675, 37: 1152, 38: 83, 39: 4613, 40: 658, 41: 2316, 42: 125478, 43: 398, 44: 125, 45: 134, 46: 154}
--------------------------------------------------
MODEL SUMMARY
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 128, 128]           9,408
       BatchNorm2d-2         [-1, 64, 128, 128]             128
              ReLU-3         [-1, 64, 128, 128]               0
         MaxPool2d-4           [-1, 64, 64, 64]               0
            Conv2d-5           [-1, 64, 64, 64]          36,864
       BatchNorm2d-6           [-1, 64, 64, 64]             128
              ReLU-7           [-1, 64, 64, 64]               0
            Conv2d-8           [-1, 64, 64, 64]          36,864
       BatchNorm2d-9           [-1, 64, 64, 64]             128
             ReLU-10           [-1, 64, 64, 64]               0
       BasicBlock-11           [-1, 64, 64, 64]               0
           Conv2d-12           [-1, 64, 64, 64]          36,864
      BatchNorm2d-13           [-1, 64, 64, 64]             128
             ReLU-14           [-1, 64, 64, 64]               0
           Conv2d-15           [-1, 64, 64, 64]          36,864
      BatchNorm2d-16           [-1, 64, 64, 64]             128
             ReLU-17           [-1, 64, 64, 64]               0
       BasicBlock-18           [-1, 64, 64, 64]               0
           Conv2d-19          [-1, 128, 32, 32]          73,728
      BatchNorm2d-20          [-1, 128, 32, 32]             256
             ReLU-21          [-1, 128, 32, 32]               0
           Conv2d-22          [-1, 128, 32, 32]         147,456
      BatchNorm2d-23          [-1, 128, 32, 32]             256
           Conv2d-24          [-1, 128, 32, 32]           8,192
      BatchNorm2d-25          [-1, 128, 32, 32]             256
             ReLU-26          [-1, 128, 32, 32]               0
       BasicBlock-27          [-1, 128, 32, 32]               0
           Conv2d-28          [-1, 128, 32, 32]         147,456
      BatchNorm2d-29          [-1, 128, 32, 32]             256
             ReLU-30          [-1, 128, 32, 32]               0
           Conv2d-31          [-1, 128, 32, 32]         147,456
      BatchNorm2d-32          [-1, 128, 32, 32]             256
             ReLU-33          [-1, 128, 32, 32]               0
       BasicBlock-34          [-1, 128, 32, 32]               0
           Conv2d-35          [-1, 256, 16, 16]         294,912
      BatchNorm2d-36          [-1, 256, 16, 16]             512
             ReLU-37          [-1, 256, 16, 16]               0
           Conv2d-38          [-1, 256, 16, 16]         589,824
      BatchNorm2d-39          [-1, 256, 16, 16]             512
           Conv2d-40          [-1, 256, 16, 16]          32,768
      BatchNorm2d-41          [-1, 256, 16, 16]             512
             ReLU-42          [-1, 256, 16, 16]               0
       BasicBlock-43          [-1, 256, 16, 16]               0
           Conv2d-44          [-1, 256, 16, 16]         589,824
      BatchNorm2d-45          [-1, 256, 16, 16]             512
             ReLU-46          [-1, 256, 16, 16]               0
           Conv2d-47          [-1, 256, 16, 16]         589,824
      BatchNorm2d-48          [-1, 256, 16, 16]             512
             ReLU-49          [-1, 256, 16, 16]               0
       BasicBlock-50          [-1, 256, 16, 16]               0
           Conv2d-51            [-1, 512, 8, 8]       1,179,648
      BatchNorm2d-52            [-1, 512, 8, 8]           1,024
             ReLU-53            [-1, 512, 8, 8]               0
           Conv2d-54            [-1, 512, 8, 8]       2,359,296
      BatchNorm2d-55            [-1, 512, 8, 8]           1,024
           Conv2d-56            [-1, 512, 8, 8]         131,072
      BatchNorm2d-57            [-1, 512, 8, 8]           1,024
             ReLU-58            [-1, 512, 8, 8]               0
       BasicBlock-59            [-1, 512, 8, 8]               0
           Conv2d-60            [-1, 512, 8, 8]       2,359,296
      BatchNorm2d-61            [-1, 512, 8, 8]           1,024
             ReLU-62            [-1, 512, 8, 8]               0
           Conv2d-63            [-1, 512, 8, 8]       2,359,296
      BatchNorm2d-64            [-1, 512, 8, 8]           1,024
             ReLU-65            [-1, 512, 8, 8]               0
       BasicBlock-66            [-1, 512, 8, 8]               0
AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0
           Linear-68                   [-1, 47]          24,111
================================================================
Total params: 11,200,623
Trainable params: 11,200,623
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.75
Forward/backward pass size (MB): 82.00
Params size (MB): 42.73
Estimated Total Size (MB): 125.48
----------------------------------------------------------------
Loaded checkpoint from epoch 1

Epoch 002 | Time: 12059.0s | Loss: 12332.9306
Train Acc: 0.7664 | Train Balanced Acc: 0.2184
Val   Acc: 0.7791 | Val   Balanced Acc: 0.2978

Epoch 003 | Time: 11542.5s | Loss: 10439.1754
Train Acc: 0.7899 | Train Balanced Acc: 0.3284
Val   Acc: 0.7941 | Val   Balanced Acc: 0.3603

Epoch 004 | Time: 11670.5s | Loss: 9544.0505
Train Acc: 0.8005 | Train Balanced Acc: 0.3874
Val   Acc: 0.8036 | Val   Balanced Acc: 0.4098

Epoch 005 | Time: 11956.0s | Loss: 8822.4785
Train Acc: 0.8096 | Train Balanced Acc: 0.4349
Val   Acc: 0.8046 | Val   Balanced Acc: 0.3962
Checkpoint saved at: D:\malnet-images\checkpoints\epoch_005.pt

Epoch 006 | Time: 14004.1s | Loss: 8193.8766
Train Acc: 0.8183 | Train Balanced Acc: 0.4860
Val   Acc: 0.8122 | Val   Balanced Acc: 0.4545

Epoch 007 | Time: 14419.8s | Loss: 7609.1068
Train Acc: 0.8263 | Train Balanced Acc: 0.5408
Val   Acc: 0.8162 | Val   Balanced Acc: 0.4444

Epoch 008 | Time: 11978.8s | Loss: 7081.5482
Train Acc: 0.8341 | Train Balanced Acc: 0.5851
Val   Acc: 0.8168 | Val   Balanced Acc: 0.4725

Epoch 009 | Time: 12223.6s | Loss: 6588.0855
Train Acc: 0.8426 | Train Balanced Acc: 0.6286
Val   Acc: 0.8207 | Val   Balanced Acc: 0.4901

Epoch 010 | Time: 11928.1s | Loss: 6134.8286
Train Acc: 0.8510 | Train Balanced Acc: 0.6578
Val   Acc: 0.8217 | Val   Balanced Acc: 0.4948
Checkpoint saved at: D:\malnet-images\checkpoints\epoch_010.pt

Epoch 011 | Time: 12013.6s | Loss: 5704.4586
Train Acc: 0.8589 | Train Balanced Acc: 0.6894
Val   Acc: 0.8249 | Val   Balanced Acc: 0.4845

Epoch 012 | Time: 12121.8s | Loss: 5321.6304
Train Acc: 0.8669 | Train Balanced Acc: 0.7138
Val   Acc: 0.8204 | Val   Balanced Acc: 0.5082

Epoch 013 | Time: 12211.2s | Loss: 4952.8645
Train Acc: 0.8743 | Train Balanced Acc: 0.7348
Val   Acc: 0.8225 | Val   Balanced Acc: 0.4890

Epoch 014 | Time: 12335.4s | Loss: 4638.9121
Train Acc: 0.8820 | Train Balanced Acc: 0.7527
Val   Acc: 0.8237 | Val   Balanced Acc: 0.5136

Epoch 015 | Time: 12442.4s | Loss: 4355.9988
Train Acc: 0.8886 | Train Balanced Acc: 0.7669
Val   Acc: 0.8236 | Val   Balanced Acc: 0.5008
Checkpoint saved at: D:\malnet-images\checkpoints\epoch_015.pt

Epoch 016 | Time: 12384.8s | Loss: 4110.7405
Train Acc: 0.8949 | Train Balanced Acc: 0.7800
Val   Acc: 0.8181 | Val   Balanced Acc: 0.4974

Epoch 017 | Time: 12439.9s | Loss: 3910.2641
Train Acc: 0.9001 | Train Balanced Acc: 0.7879
Val   Acc: 0.8272 | Val   Balanced Acc: 0.4758

Epoch 018 | Time: 12487.4s | Loss: 3727.1629
Train Acc: 0.9049 | Train Balanced Acc: 0.7967
Val   Acc: 0.8213 | Val   Balanced Acc: 0.5065

Epoch 019 | Time: 12523.2s | Loss: 3568.6523
Train Acc: 0.9086 | Train Balanced Acc: 0.8064
Val   Acc: 0.8198 | Val   Balanced Acc: 0.5163

Epoch 020 | Time: 12429.3s | Loss: 3418.2915
Train Acc: 0.9125 | Train Balanced Acc: 0.8133
Val   Acc: 0.8233 | Val   Balanced Acc: 0.4952
Checkpoint saved at: D:\malnet-images\checkpoints\epoch_020.pt

Epoch 021 | Time: 10417.3s | Loss: 3297.2136
Train Acc: 0.9154 | Train Balanced Acc: 0.8166
Val   Acc: 0.8227 | Val   Balanced Acc: 0.5045

Epoch 022 | Time: 10240.5s | Loss: 3187.1361
Train Acc: 0.9184 | Train Balanced Acc: 0.8243
Val   Acc: 0.8264 | Val   Balanced Acc: 0.5106

Epoch 023 | Time: 10248.6s | Loss: 3076.9984
Train Acc: 0.9211 | Train Balanced Acc: 0.8294
Val   Acc: 0.8220 | Val   Balanced Acc: 0.4660

Epoch 024 | Time: 10082.0s | Loss: 2992.6272
Train Acc: 0.9231 | Train Balanced Acc: 0.8311
Val   Acc: 0.8198 | Val   Balanced Acc: 0.5054

Epoch 025 | Time: 10219.3s | Loss: 2915.4901
Train Acc: 0.9253 | Train Balanced Acc: 0.8348
Val   Acc: 0.8227 | Val   Balanced Acc: 0.4992
Checkpoint saved at: D:\malnet-images\checkpoints\epoch_025.pt

Epoch 026 | Time: 10241.1s | Loss: 2825.3621
Train Acc: 0.9272 | Train Balanced Acc: 0.8399
Val   Acc: 0.8251 | Val   Balanced Acc: 0.5030

Epoch 027 | Time: 10267.6s | Loss: 2763.4093
Train Acc: 0.9288 | Train Balanced Acc: 0.8408
Val   Acc: 0.8236 | Val   Balanced Acc: 0.5017

Epoch 028 | Time: 10180.0s | Loss: 2700.6319
Train Acc: 0.9301 | Train Balanced Acc: 0.8430
Val   Acc: 0.8251 | Val   Balanced Acc: 0.5074

Epoch 029 | Time: 10109.6s | Loss: 2640.7422
Train Acc: 0.9319 | Train Balanced Acc: 0.8467
Val   Acc: 0.8205 | Val   Balanced Acc: 0.5030
